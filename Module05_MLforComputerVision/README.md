# Module 05: Machine Learning for Computer Vision

## Summary
In Module 05, we endured the fundamentals of machine learning applied to image classification using classical ML techniques. The focus was on understanding the difference between supervised and unsupervised learning, and we got hands-on experience training models using Support Vector Machines (SVM) with image data.

For this module, our team worked with two Jupyter notebooks. The first used the CIFAR-10 dataset to demonstrate image classification with SVM, while the second had us build a classifier using a custom dataset of cats and dogs from Kaggle. Both notebooks required us to preprocess image data, extract features, and train models using the Scikit-Learn library.

I personally found the CIFAR-10 notebook more straightforward, especially with loading the dataset and converting images to grayscale. However, the custom dataset notebook was more challenging — handling ZIP files from Kaggle, organizing images, and dealing with errors in Google Colab pushed my comfort zone. With the help of my team, ChatGPT, and Gemini, I was able to get the model to classify dog images successfully, which felt like a huge win.

This module taught me a lot about data handling, the patience needed to troubleshoot notebooks, and how real-world ML workflows are much more than just clicking "Run." I’m starting to understand how all the concepts — from feature extraction to model training — come together in AI applications.

## Files Included
- L05_CamerounWhite_EyeConic_ITAI1378.docx
